{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel():\n",
    "    def __init__(self, order=2):\n",
    "        self.order=order\n",
    "        \n",
    "    def product(self, nums):\n",
    "        \"Multiply the numbers together.  (Like `sum`, but with multiplication.)\"\n",
    "        result = 1\n",
    "        for x in nums: result *= x\n",
    "        return result\n",
    "\n",
    "    def get_ngrams(self, tokens, n):\n",
    "        return [' '.join(tokens[i:i+n]) for i, token in enumerate(tokens)]\n",
    "    \n",
    "    def get_counts(self, corpus, order):  \n",
    "        counts = {'n' + str(i) : Counter(self.get_ngrams(corpus, n=i)) for i in range(1, order+1)}\n",
    "        counts['n0'] = {'':len(corpus)}\n",
    "        return counts\n",
    "    \n",
    "    def get_prob(self, counts, word, context=''):\n",
    "        '''With Laplace shoothing as yet.\n",
    "        Not for public use.'''\n",
    "        order = len(context.split())+1\n",
    "        separator = ' ' if order > 1 else ''\n",
    "        return (counts['n'+str(order)][separator.join([context, word])] + 1) / \\\n",
    "               (counts['n'+str(order-1)][context] + len(counts['n'+str(order)]))\n",
    "        \n",
    "    def get_logprob(self, counts, word, context=''):\n",
    "        return np.log(self.get_prob(counts, word, context))\n",
    "    \n",
    "    def get_following(self, counts, context):\n",
    "        '''Slow as hell. \n",
    "        To optimize might use embedded dictionaries.'''\n",
    "        order = len(context.split())+1\n",
    "        return sorted(\n",
    "            [(k.split()[-1], v, self.get_prob(counts, k.split()[-1], context)) \\\n",
    "            for k, v in counts['n'+str(order)].items()                         \\\n",
    "            if re.match(context+' '+'\\w+', k)],                                \\\n",
    "            key=lambda x:x[1], reverse=True)   \n",
    "    \n",
    "    def get_string_probs(self, counts, string, order, log=True):\n",
    "        prob_fun = self.get_logprob if log else self.get_prob\n",
    "        tokens = string.split()\n",
    "        probs = []\n",
    "        for i in range(len(tokens)):\n",
    "            context = ' '.join(tokens[i-order+1:i]) if i>=order else ' '.join(tokens[:i])\n",
    "            prob = prob_fun(counts, word = tokens[i], context = context)\n",
    "            probs.append(prob)\n",
    "        return probs\n",
    "    \n",
    "    def interpolate(self, counts, string, order, log=True, lambdas='default'):\n",
    "        lmbd = [0.3, 0.7, 0.0] if lambdas == 'default' else lambdas\n",
    "        aggregate = sum if log else self.product\n",
    "        probs = [self.get_string_probs(counts, string, order=i, log=log) \\\n",
    "                 for i in range(1, order+1)]\n",
    "        probs_interpolated = []\n",
    "        for tup in zip(*probs):\n",
    "            prob_token = 0\n",
    "            for i in range(len(tup)):\n",
    "                prob_token += tup[i] * lmbd[i]\n",
    "            probs_interpolated.append(prob_token)\n",
    "        return aggregate(probs_interpolated)\n",
    "    \n",
    "    def fit(self, corpus):\n",
    "        self.counts = self.get_counts(corpus, self.order)\n",
    "        \n",
    "    def prob(self, string, log=False):\n",
    "        return self.interpolate(self.counts, string, self.order, log=log)\n",
    "    \n",
    "    def context_prob(self, word, context='', log=False):\n",
    "        prob_fun = self.get_logprob if log else self.get_prob\n",
    "        c = context.split()\n",
    "        history = ' '.join(c) if len(c) < self.order else ' '.join(c[-self.order+1:])\n",
    "        return prob_fun(self.counts, word, history)  \n",
    "    \n",
    "    def following(self, context):\n",
    "        c = context.split()\n",
    "        history = ' '.join(c) if len(c) < self.order else ' '.join(c[-self.order+1:])\n",
    "        return self.get_following(self.counts, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(s, rgxp = '[\\W\\da-z]'):\n",
    "    return re.sub(' +', ' ', re.sub(rgxp, ' ', s.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lt1.txt', encoding='utf-8') as f:\n",
    "    tokens = cleanse(f.read().lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 962 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = LanguageModel(order=2)\n",
    "model.fit(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001646777278875629"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.prob('наташа')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0009444457784076e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.prob('череззаборногузадирищекно')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.515250993684362e-19"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.prob('наташа и пьер не хотели ехать')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6336287741983484e-21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.prob('наташа и череззаборногузадирищекно не хотели ехать')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00019359544774132881"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.context_prob('наташа', 'и')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00019359544774132881"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.context_prob('наташа', 'герцог чубакка и')\n",
    "# same as previous cause model with order 2 (bigram) takes into consideration only k-1 word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 570 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('что', 2, 1.1212354519700106e-05),\n",
       " ('бы', 1, 7.474903013133404e-06),\n",
       " ('обман', 1, 7.474903013133404e-06),\n",
       " ('в', 1, 7.474903013133404e-06),\n",
       " ('неприятеля', 1, 7.474903013133404e-06),\n",
       " ('выезжая', 1, 7.474903013133404e-06),\n",
       " ('старшего', 1, 7.474903013133404e-06),\n",
       " ('молодое', 1, 7.474903013133404e-06)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.following('увидел')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 559 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('что', 2, 1.1212354519700106e-05),\n",
       " ('бы', 1, 7.474903013133404e-06),\n",
       " ('обман', 1, 7.474903013133404e-06),\n",
       " ('в', 1, 7.474903013133404e-06),\n",
       " ('неприятеля', 1, 7.474903013133404e-06),\n",
       " ('выезжая', 1, 7.474903013133404e-06),\n",
       " ('старшего', 1, 7.474903013133404e-06),\n",
       " ('молодое', 1, 7.474903013133404e-06)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.following('когда утуб наконец-то загрузился он увидел')\n",
    "# same as previous cause model with order 2 (bigram) takes into consideration only k-1 word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 558 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.following('чубакка')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1 [('и', 21710), ('в', 11173), ('не', 8781), ('что', 8367), ('он', 7493), ('на', 6796)]\n",
      "n2 [('что он', 861), ('князь андрей', 778), ('и не', 725), ('то что', 666), ('и в', 498), ('сказал он', 488)]\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.counts.items():\n",
    "    if k != 'n0': print(k, v.most_common(6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
